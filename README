To run the code, which was written using numpy and scipy, run

$ python code/benchmark.py

The benchmark file will test the Decision Tree, Random Forest, and AdaBoost and return the appropriate training/test error rates.

The majority of the code is in:

collection.py (an abstraction on the data that allows for easy partitioning, sorting, and splitting)
tree.py (the decision tree node/leaf abstraction)
classifier.py (the main code for the 3 classifiers, which rely on each other heavily)


To run the matlab code, run 

$ matlab
>> main(0.039, 400, 0)

The parameter of the main method are as follows.
main(beta, numThresholdsPerFeature, recursiveDepth)

Beta is the minimum amount of information gain before we decide to cut
NumThresholdsPerFeature is the maxinum number of threshold values we will have per feature
Recursive depth is the amount of lookahead we will do. I recommend doing no greater than 1 or else it will take a very long time to run.
